# -*- coding: utf-8 -*-
"""Sumit Kamble - Bike Sharing Demand Prediction - Capstone Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Ed6f2sQob_Y_YbYTYnJ2ZfQLONb75BF

# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>

## <b> Problem Description </b>

### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.

## <b> Data Description </b>

### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>


### <b>Attribute Information: </b>

* ### Date : year-month-day
* ### Rented Bike count - Count of bikes rented at each hour
* ### Hour - Hour of he day
* ### Temperature-Temperature in Celsius
* ### Humidity - %
* ### Windspeed - m/s
* ### Visibility - 10m
* ### Dew point temperature - Celsius
* ### Solar radiation - MJ/m2
* ### Rainfall - mm
* ### Snowfall - cm
* ### Seasons - Winter, Spring, Summer, Autumn
* ### Holiday - Holiday/No holiday
* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)
"""

## Importing necessary library 
import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

## read csv file using pandas
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/module 4/Capstone project Bike Sharing Prediction Regression/SeoulBikeData2.csv')

df.head()

# To check how many rows and columns
df.shape

df.describe()

## Cheking null values and data type
df.info()

"""*   No null values in the data 
*   Data type contain integer, float and objective

## ***Data Preprcessing***

---



---
"""

## change date to perfect date format
df['Date']=pd.to_datetime(df['Date'],format="%d-%m-%Y")

## Adding new month column with mont format
 
frame = pd.to_datetime(df['Date'], dayfirst = True)
frame = pd.DataFrame([frame]).transpose()
frame['Date']= frame
frame['month']= frame['Date'].dt.month
df['Month'] = frame['month']

## converting date format to Weekdays like Sunday, Monday, tuesday, Wednsday, thursday, Friday and saturday 

df['WeekDay']=df["Date"].dt.day_name()

## Drop entire Date column whilw modeling we don't need Dates 

df = df.drop(columns=['Date'])

## unique values
df.apply(lambda x: len(x.unique()))

# Checking if any null values in every columns 

df.isnull().sum()

"""There are no null values present in the rows

# **Exploratory Data Analysis**

---



---
"""

import matplotlib.pyplot as plt
import seaborn as sns

df.groupby('Seasons').sum()['Rented Bike Count'].plot.pie(figsize=(10,10),autopct='%1.1f%%')

"""From the above pie graph we can say that the largest number of bikes rented in Summer and Spring Seasons as well as Autumn season And In winter season rate of ranting bike is decreases.

The reason behind decreasing rate of ranting bike is that the temperature is below 0 in that situation evryone dont wants to go outside with bikes, might be they prefer travelling with there own cars or buses where temperature is maintain.

"""

## Bar plot of Weekdays with respect to Rented Bike Count
plt.subplots(figsize = (12,8))
df.groupby('WeekDay').sum()['Rented Bike Count'].plot.bar()

"""From the above graph we can't see any major difference renting bikes during weekdays.

But in sunday renting bike is lower than other days, it may happen because of holiday.
"""

## Scatter plot for looking relation between Temperature(°C) and Rented Bike Count
## Scatter plot for looking relation between Humidity(%) and Rented Bike Count

fig, (ax1,ax2) = plt.subplots(ncols = 2, figsize = (20,6))
sns.regplot(x = df['Temperature(°C)'], y=df['Rented Bike Count'], ax=ax1)
ax1.set(title = 'Relation Between Temperature and users')
sns.regplot(x=df['Humidity(%)'], y=df['Rented Bike Count'], ax=ax2)
ax2.set(title = 'Relation Between Humidity and users')

"""From the above first graph shows relation between Temperature(°C) and Rented Bike Count. Clearly It shows relation between Temperature(°C) and Rented Bike Count. When Temperature is increases, Rented Bike count is increases.

From the above second graph shows relation between Humidity(%)) and Rented Bike Count. We can't see any relation.
"""

## Scatter plot for looking relation between Visibility (10m) and Rented Bike Count 

fig, (ax1) = plt.subplots(figsize = (12,8))
sns.regplot(x = df['Visibility (10m)'], y=df['Rented Bike Count'], ax=ax1)

"""From the above graph we can not see any relation between Visibility (10m) and Rented Bike Count """

## Scater plot between Dew point temperature(°C) and Rented Bike Count.

fig, (ax1) = plt.subplots(figsize = (12,8))
sns.regplot(x = df['Dew point temperature(°C)'], y=df['Rented Bike Count'], ax=ax1)

"""From the above graph we can see the relation. the relation is same as relation between temperature and rented bike count"""

## Scatter plot between Solar Radiation (MJ/m2) and Rented Bike Count

fig, (ax1) = plt.subplots(figsize = (12,8))
sns.regplot(x = df['Solar Radiation (MJ/m2)'], y=df['Rented Bike Count'], ax=ax1)

"""From the above graph we can not see relation."""

## Scatter plot between Rainfall(mm) and Rented Bike Count

fig, (ax1) = plt.subplots(figsize = (12,8))
sns.regplot(x = df['Rainfall(mm)'], y=df['Rented Bike Count'], ax=ax1)

"""If no rainfall the rented bike count is highest.. """

## Scatter plot between Snowfall (cm) and Rented Bike Count..

fig, (ax1) = plt.subplots(figsize = (12,8))
sns.regplot(x = df['Snowfall (cm)'], y=df['Rented Bike Count'], ax=ax1)

"""If there is no snowfall the rented bike count is highest"""

### Pie plot between Holiday and Rented Bike Count

df.groupby('Holiday').sum()['Rented Bike Count'].plot.pie()

"""The rented bike count is highest when no holiday. 

from the above we can say the bike is rented by working people. 
"""

## Pie Plot between Functioning Day and Rented Bike Count
df.groupby('Functioning Day').sum()['Rented Bike Count'].plot.pie()

"""All day is functioning day."""

## Point plot between Hour and Rented Bike Count

fig, ax = plt.subplots(figsize = (20,10))
sns.pointplot(data = df, x = 'Hour', y = 'Rented Bike Count', ax = ax)

"""From above graph we can say that.

Bike sharing starts from the morning at 6 am it is getting traction till 8 am, slowly its slowing down to 10am. we can consider that some many people go to office and another place in the morning thats why its getting peak from 6 am to 10 am.

Again in the evening from 4 pm to 8 pm getting traction. From that we can consider people coming back to home. After that bike renting go down till the night time. 
"""

## Point plot between Hour and Rented Bike Count during weekdays

fig, ax = plt.subplots(figsize = (20,10))
sns.pointplot(data = df, x = 'Hour', y = 'Rented Bike Count', hue='WeekDay' ,ax = ax)
ax.set(title = 'Rented Bike Count during weekdays')

"""From the above graph we can say that bike count in monday, Tuesday, Wednseday, Thursday, Friday is same as previous graph 

But in Saturday and Sunday graph shows differnt pattern it ois different from another days. From 10 am to 9 pm getting traction. People go out for vaccations and some other purpose. In the weekends getting so many users in the afternoon and evening time.
"""

## Point plot between Hour and Rented Bike Count during Seasons

fig, ax = plt.subplots(figsize = (20,10))
sns.pointplot(data = df, x = 'Hour', y = 'Rented Bike Count', hue='Seasons' ,ax = ax)
ax.set(title = 'Rented Bike Count during different Seasons')

"""From above graph the renting bike in a spring,autumn and summer season is hightest.

But In winter season the rate of renting bike is decreases, the reason behind that the temperature is very low because of people don't wants to renting bike and the may prefer travelling with vehicle where temperature maintained.
"""

## Bar plot between Months and Rented Bike Count.

fig, ax = plt.subplots(figsize = (20,10))
sns.barplot(data = df, x = 'Month', y = 'Rented Bike Count', ax = ax)
ax.set(title = 'Rented Bike Count in Month')

"""The above graph shows uniform distribution, The seasons are defined as spring (March, April, May), summer (June, July, August), autumn (September, October, November) and winter (December, January, February).

The rate of renting bike is increases from march month which is under spring season, highest peak of renting bikes in june month which is under summer season, after that renting bike rate is decreases from december to february which is under winter season.

# **Data Preparation**

---



---
"""

## Making duplicate data with using copy, we don't want to any changes in original data

df_pre = df.copy()

df_pre.head(1)

## One hot code

df_pre = pd.get_dummies(df_pre, columns=["Seasons", "WeekDay"], prefix=["seasons", "weekday"])

## Adding new column name "holiday" with binary values.
df_pre['holiday'] = df_pre['Holiday'].apply(lambda x : 0 if x == 'No Holiday' else 1)

## Adding new column name "functioning_day" with binary values.
df_pre['functioning_day'] = df_pre['Functioning Day'] .apply(lambda x : 1 if x == 'Yes' else 0)

## deleting "Holiday" and "Functioning Day" column because we don't need this data while modeling.
df_pre = df_pre.drop(columns=['Holiday', "Functioning Day"])

df_pre.head(2)

## Deleting Null values if iny present in data
df_pre.dropna(inplace=False)

"""# **Model Training**

---



--
"""

## Training and spliting the data training data is 80% of the data and 20% data is for testing.

from sklearn.model_selection import train_test_split 
X = df_pre.drop(columns=["Rented Bike Count", "Humidity(%)", "Wind speed (m/s)", 
                         "Visibility (10m)", "Dew point temperature(°C)", "Solar Radiation (MJ/m2)"])

Y = df_pre['Rented Bike Count']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 51)
print(X_train.shape)
print(X_test.shape)

"""**LinearRegression**"""

## importing LinearRegression and ridge from sklearn
from sklearn.linear_model import LinearRegression, Ridge
reg = LinearRegression().fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage 
reg.score(X_test, Y_test) * 100

"""The score is very less we will not use this regression

**r2 Score**
"""

## importing r2 score from sklearn.matricd
from sklearn.metrics import r2_score
y_pred_train = reg.predict(X_train)
y_pred = reg.predict(X_test)
r2_score(Y_train, y_pred_train) * 100

"""The score is very less we will not use this regression"""

ridge = Ridge(alpha = 10)
 ridge.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage 
ridge.score(X_test, Y_test) * 100

"""The score is very less we will not use this regression

**Lasso Regression**
"""

## importing Lasso and LassoCV from sklearn.linearmodel
from sklearn.linear_model import Lasso, LassoCV

lasso = Lasso()
lasso.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage 
lasso.score(X_test, Y_test) *100

"""The score is very less we will not use this regression"""

lassocv = LassoCV()
lassocv.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage 
lassocv.score(X_test, Y_test) *100

"""The score is very less we will not use this regression"""

y_pred = reg.predict(X_test)

y_pred_train = reg.predict(X_train)

## finding score or predicting values and compairing in percentage 
r2_score(Y_test, y_pred) * 100

"""The score is very less we will not use this regression

**ElasticNet Regression**
"""

## Import ElasticNet from sklearn linearmodel
from sklearn.linear_model import ElasticNet

elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)

## Fitting training data in ElasticNet Model
elasticnet.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage 
elasticnet.score(X_test, Y_test) *100

"""The score is very less we will not use this regression

**KNeighborsRegressor**

---



---
"""

## Import K nearest neighbor regressor from sklearn neighbors
from sklearn.neighbors import KNeighborsRegressor
 
## Fitting training data in KNeighborsRegressor Model
Knn_regressor = KNeighborsRegressor(n_neighbors=5)
Knn_regressor.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage 
Knn_regressor.score(X_test, Y_test) *100

"""The Score is under good condition we can use this alogorithm, 
but we can use another algorithm if any increasing in accuracy.

**DecisionTreeRegressor**

---



---
"""

## Import DecisionTreeRegressor from sklearn tree
from sklearn.tree import DecisionTreeRegressor

## Fiting training data in DecisionTreeRegressor
dc_regressor = DecisionTreeRegressor(criterion='mse')
dc_regressor.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage
dc_regressor.score(X_test, Y_test) * 100

"""we can see the above score the score is improved so we can use this algorithm for deploying

but we use another algorithm to see if any improvement in another model

**RandomForestRegressor**

---



---



---
"""

## Import Random Forest Regressor from sklearn ensemble
from sklearn.ensemble import RandomForestRegressor
Rand_regressor = RandomForestRegressor(n_estimators=105, criterion='mse')

## Fiting training data in RandomForestRegressor model
Rand_regressor.fit(X_train, Y_train)

## finding score or predicting values and compairing in percentage
Rand_regressor.score(X_test, Y_test)*100

"""we can see the above score, the score is improved so we can use this algorithm for deploying """